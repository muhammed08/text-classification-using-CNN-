{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "TensorFlow-GPU",
      "language": "python",
      "name": "project"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "text_classi_bbc_gpu.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-PtqF-n3u57",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83
        },
        "outputId": "b6fd3f91-3017-40d2-983a-4f8a7a1980ec"
      },
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import keras\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers import Dense, Input, Flatten, Dropout, Add\n",
        "from keras.layers import Conv1D, MaxPooling1D, Embedding\n",
        "from keras.models import Model\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.layers.merge import concatenate, add"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7629d39c-3376-4028-b830-9660ad8b1a4f",
        "id": "XWpQ0abb4_y7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 128
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDwHK2_v5P1l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/My Drive/dataset/bbc-text.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_IoXp0m3u6W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "1d71d1f3-9e96-49dd-f83a-5b04a8af5db1"
      },
      "source": [
        "dataset.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>category</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>tech</td>\n",
              "      <td>tv future in the hands of viewers with home th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>business</td>\n",
              "      <td>worldcom boss  left books alone  former worldc...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>sport</td>\n",
              "      <td>tigers wary of farrell  gamble  leicester say ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sport</td>\n",
              "      <td>yeading face newcastle in fa cup premiership s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>entertainment</td>\n",
              "      <td>ocean s twelve raids box office ocean s twelve...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        category                                               text\n",
              "0           tech  tv future in the hands of viewers with home th...\n",
              "1       business  worldcom boss  left books alone  former worldc...\n",
              "2          sport  tigers wary of farrell  gamble  leicester say ...\n",
              "3          sport  yeading face newcastle in fa cup premiership s...\n",
              "4  entertainment  ocean s twelve raids box office ocean s twelve..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWetiwFZ3u6f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = dataset.iloc[:,-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uv-EKZS13u6n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "943a6119-d0bc-43d2-e7d9-fb894f0c435b"
      },
      "source": [
        "X.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    tv future in the hands of viewers with home th...\n",
              "1    worldcom boss  left books alone  former worldc...\n",
              "2    tigers wary of farrell  gamble  leicester say ...\n",
              "3    yeading face newcastle in fa cup premiership s...\n",
              "4    ocean s twelve raids box office ocean s twelve...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWUOTcNY3u6v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "Y = dataset.iloc[:,0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qA2jBhEk3u62",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "d1e9afed-84ad-4366-bd3c-d74a2a93cb62"
      },
      "source": [
        "dataset['category'].value_counts()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sport            511\n",
              "business         510\n",
              "politics         417\n",
              "tech             401\n",
              "entertainment    386\n",
              "Name: category, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Nv9zVsq3u68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lb = LabelEncoder()\n",
        "temp = lb.fit_transform(Y)\n",
        "y = to_categorical(temp)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ovsK7xI03u7D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4e48dc28-0aac-4438-dcc8-7e282e63213d"
      },
      "source": [
        "y[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0., 0., 0., 0., 1.], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M07cDFoS3u7K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "outputId": "965499ae-07e0-430a-b780-ace8a9883699"
      },
      "source": [
        "text = dataset['text']\n",
        "tokenizer = Tokenizer(\n",
        "    num_words = None,\n",
        "    char_level=False,\n",
        "    lower=True,\n",
        "    split = ' ',\n",
        "    filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'\n",
        ")\n",
        "tokenizer.fit_on_texts(text)\n",
        "sequences = tokenizer.texts_to_sequences(text)\n",
        "print(sequences[0])\n",
        "max_len = 0\n",
        "for i in sequences:\n",
        "  l = len(i)\n",
        "  if max_len < l:\n",
        "    max_len = l\n",
        "    \n",
        "print(max_len)\n",
        "\n",
        "padded_sequences = pad_sequences(sequences, maxlen=max_len)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[176, 264, 6, 1, 1252, 3, 1315, 17, 126, 1216, 838, 5277, 162, 1168, 4339, 4, 235, 272, 4201, 1440, 76, 1, 1407, 1685, 1, 117, 47, 1044, 176, 23, 16, 6572, 422, 6, 172, 79, 67, 10, 9, 228, 2, 34, 3207, 1426, 35, 2599, 21, 1, 676, 516, 1373, 149, 6, 3042, 3125, 2, 1843, 130, 182, 48, 991, 23, 852, 50, 3, 125, 1049, 19534, 17, 1, 49, 752, 1, 1668, 1147, 4, 71, 511, 23, 16, 2085, 2, 1315, 875, 126, 601, 179, 1589, 2198, 1742, 223, 4, 427, 209, 2824, 2, 914, 5278, 4, 1182, 707, 50, 3, 1, 116, 4483, 52, 991, 3, 2660, 19, 38, 235, 4, 447, 272, 4201, 8861, 4, 5858, 182, 112, 150, 3296, 92, 1, 49, 7, 5538, 4, 1, 77, 7, 1492, 233, 553, 47, 2, 226, 1493, 159, 4665, 4, 587, 5279, 176, 1147, 66, 29, 164, 6573, 1, 160, 2199, 8, 140, 40, 8862, 176, 29, 25, 45, 88, 1217, 6, 2, 162, 1168, 176, 2056, 35, 25, 236, 247, 6, 517, 4, 1, 49, 24, 2958, 2, 114, 128, 6, 237, 102, 3, 1, 1316, 3, 162, 1168, 4484, 28, 85, 55, 47, 587, 5279, 179, 3208, 29, 55, 45, 2773, 52, 7022, 22, 509, 4, 1191, 8863, 1471, 713, 39, 207, 5, 2164, 14999, 853, 24, 75, 49, 601, 4, 1589, 4, 2198, 223, 25, 2005, 52, 74, 11, 507, 8, 82, 6, 992, 3, 2165, 1708, 18, 111, 18, 1906, 2661, 4, 5062, 5539, 2, 2600, 339, 1, 49, 2715, 6, 33, 160, 21, 1, 915, 11, 9, 45, 5, 1183, 10, 9, 88, 1227, 6, 237, 894, 17, 1, 677, 8864, 3, 224, 92, 1492, 74, 1907, 496, 544, 31, 23, 169, 6, 1050, 201, 2, 5, 79, 67, 6, 1, 77, 3473, 19535, 1, 110, 1547, 7, 12633, 89, 1, 110, 180, 458, 8, 1, 2476, 3, 1, 110, 51, 25, 80, 563, 3, 330, 2165, 1472, 435, 11, 9, 5, 40, 5540, 419, 21, 1, 915, 8, 1228, 77, 2716, 24, 1906, 5539, 9, 388, 8, 832, 31, 23, 16, 1271, 40, 52, 511, 2128, 497, 57, 509, 2128, 13, 1408, 12634, 27, 1906, 1940, 147, 19536, 19537, 1, 1881, 9, 10, 17, 427, 1908, 3474, 55, 16, 1, 1296, 3, 511, 15, 118, 1, 954, 72, 9, 10, 11, 9, 358, 2, 3043, 5, 462, 17, 73, 140, 671, 74, 33, 507, 13, 19538, 19539, 767, 1409, 293, 3, 176, 4068, 176, 189, 9, 10, 1, 117, 47, 448, 1, 511, 29, 164, 2, 1044, 19, 2, 16, 15000, 8, 176, 1315, 11, 507, 10, 601, 6, 49, 992, 56, 2600, 61, 114, 5, 10960, 53, 3, 948, 7, 646, 4, 16, 1, 500, 1941, 3, 1, 264, 672, 3, 1, 19540, 2, 229, 47, 448, 74, 29, 164, 2, 1044, 33, 1297, 3, 1191, 1590, 464, 145, 8, 1, 2129, 1358, 883, 35, 9, 174, 2, 350, 390, 3, 39, 1125, 4, 74, 29, 159, 12, 82, 24, 11, 464, 28, 2662, 832, 1, 1426, 2384, 1757, 7023, 25, 40, 3923, 17, 3297, 8863, 4, 1191, 2128, 102, 29, 273, 74, 29, 25, 491, 29, 1646, 84, 28, 164, 73, 140, 3, 1, 671, 198, 76, 39, 1252, 32, 12634, 1070, 12, 1, 71, 181, 59, 20, 1, 3298, 86, 53, 3, 19541, 46, 25, 2431, 8865, 197, 866, 9, 534, 4, 539, 2, 82, 13, 32, 12634, 2717, 1, 516, 23, 1591, 1, 119, 29, 164, 3, 1, 522, 104, 48, 1125, 4, 991, 88, 7024, 21, 2660, 99, 3, 82, 25, 52, 4340, 1, 176, 1810, 949, 162, 1168, 176, 2056, 25, 7573, 4, 99, 48, 1607, 3, 7025, 7026, 4202, 1562, 4339, 20, 38, 744, 17, 8861, 3924, 1217, 76, 82, 672, 3, 88, 4203, 3296, 50, 94, 1007, 744, 21, 1, 149, 9, 19542, 7, 1441, 6197, 7025, 176, 17, 34, 1563, 1102, 5538, 8861, 4, 685, 4204, 50, 3, 1, 49, 7, 335, 2198, 176, 223, 19543, 19, 190, 744, 43, 207, 3126, 8861, 21, 1, 149, 17, 599, 808, 3, 2555, 3924, 5280, 3591, 4, 5, 500, 4862, 1, 112, 55, 4665, 4, 9796, 176, 8, 42, 2, 1864, 808, 4, 387, 208, 378, 2888, 439, 6, 30, 753, 149, 4069, 859, 5, 3814, 17, 5538, 251, 19544, 35, 507, 47, 55, 159, 1865, 1147, 12, 921, 971, 4, 168, 707, 58, 182, 3209, 1, 1473, 1668, 3, 9797, 42, 1758, 73, 10, 47, 55, 1044, 74, 29, 164, 66, 29, 164]\n",
            "4491\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFzaNSvG3u7Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_words = vocab_size = len(tokenizer.word_index) + 1\n",
        "embedding_dim = 128\n",
        "max_sequence_length = max_len\n",
        "extra_conv = True\n",
        "labels_index = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqLSqGVE3u7X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 400
        },
        "outputId": "bf7e5047-0b29-4ff4-8d85-ca2d855c286d"
      },
      "source": [
        "embedding_layer = Embedding(num_words,\n",
        "                            embedding_dim,\n",
        "                            input_length=max_sequence_length)\n",
        "\n",
        "sequence_input = Input(shape=(max_sequence_length,))\n",
        "\n",
        "embedded_sequences = embedding_layer(sequence_input)\n",
        "convs = []\n",
        "filter_sizes = [4,5,6] # in the loop, first apply 3 as size, then 4 then 5\n",
        "\n",
        "for filter_size in filter_sizes:\n",
        "    l_conv = Conv1D(filters=128, kernel_size=filter_size, activation='relu')(embedded_sequences)\n",
        "    #kernel is the filter\n",
        "    l_pool = MaxPooling1D(pool_size=3)(l_conv)\n",
        "    convs.append(l_pool)\n",
        "\n",
        "l_merge = concatenate(convs, axis=1)\n",
        "\n",
        "    \n",
        "conv = Conv1D(filters=128, kernel_size=3, activation='relu')(embedded_sequences)\n",
        "pool = MaxPooling1D(pool_size=3)(conv)\n",
        "\n",
        "if extra_conv==True:\n",
        "    x = Dropout(0.5)(l_merge)  \n",
        "else:\n",
        "        # Original Yoon Kim model\n",
        "    x = Dropout(0.5)(pool)\n",
        "x = Flatten()(x)\n",
        "x = Dense(128, activation='relu')(x)\n",
        "x = Dropout(0.5)(x)\n",
        "    \n",
        "preds = Dense(labels_index, activation='softmax')(x)\n",
        "\n",
        "model = Model(sequence_input, preds)\n",
        "model.compile(loss='binary_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['acc'])"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4267: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3657: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gat-z6jY3u7d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "58c19782-2248-4e40-a9b4-e38cde367922"
      },
      "source": [
        "x_complete = pd.DataFrame(padded_sequences)\n",
        "x_complete.head()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>4451</th>\n",
              "      <th>4452</th>\n",
              "      <th>4453</th>\n",
              "      <th>4454</th>\n",
              "      <th>4455</th>\n",
              "      <th>4456</th>\n",
              "      <th>4457</th>\n",
              "      <th>4458</th>\n",
              "      <th>4459</th>\n",
              "      <th>4460</th>\n",
              "      <th>4461</th>\n",
              "      <th>4462</th>\n",
              "      <th>4463</th>\n",
              "      <th>4464</th>\n",
              "      <th>4465</th>\n",
              "      <th>4466</th>\n",
              "      <th>4467</th>\n",
              "      <th>4468</th>\n",
              "      <th>4469</th>\n",
              "      <th>4470</th>\n",
              "      <th>4471</th>\n",
              "      <th>4472</th>\n",
              "      <th>4473</th>\n",
              "      <th>4474</th>\n",
              "      <th>4475</th>\n",
              "      <th>4476</th>\n",
              "      <th>4477</th>\n",
              "      <th>4478</th>\n",
              "      <th>4479</th>\n",
              "      <th>4480</th>\n",
              "      <th>4481</th>\n",
              "      <th>4482</th>\n",
              "      <th>4483</th>\n",
              "      <th>4484</th>\n",
              "      <th>4485</th>\n",
              "      <th>4486</th>\n",
              "      <th>4487</th>\n",
              "      <th>4488</th>\n",
              "      <th>4489</th>\n",
              "      <th>4490</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>5</td>\n",
              "      <td>3814</td>\n",
              "      <td>17</td>\n",
              "      <td>5538</td>\n",
              "      <td>251</td>\n",
              "      <td>19544</td>\n",
              "      <td>35</td>\n",
              "      <td>507</td>\n",
              "      <td>47</td>\n",
              "      <td>55</td>\n",
              "      <td>159</td>\n",
              "      <td>1865</td>\n",
              "      <td>1147</td>\n",
              "      <td>12</td>\n",
              "      <td>921</td>\n",
              "      <td>971</td>\n",
              "      <td>4</td>\n",
              "      <td>168</td>\n",
              "      <td>707</td>\n",
              "      <td>58</td>\n",
              "      <td>182</td>\n",
              "      <td>3209</td>\n",
              "      <td>1</td>\n",
              "      <td>1473</td>\n",
              "      <td>1668</td>\n",
              "      <td>3</td>\n",
              "      <td>9797</td>\n",
              "      <td>42</td>\n",
              "      <td>1758</td>\n",
              "      <td>73</td>\n",
              "      <td>10</td>\n",
              "      <td>47</td>\n",
              "      <td>55</td>\n",
              "      <td>1044</td>\n",
              "      <td>74</td>\n",
              "      <td>29</td>\n",
              "      <td>164</td>\n",
              "      <td>66</td>\n",
              "      <td>29</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>1710</td>\n",
              "      <td>4342</td>\n",
              "      <td>1236</td>\n",
              "      <td>330</td>\n",
              "      <td>52</td>\n",
              "      <td>8152</td>\n",
              "      <td>4</td>\n",
              "      <td>367</td>\n",
              "      <td>104</td>\n",
              "      <td>861</td>\n",
              "      <td>330</td>\n",
              "      <td>39</td>\n",
              "      <td>501</td>\n",
              "      <td>32</td>\n",
              "      <td>1743</td>\n",
              "      <td>658</td>\n",
              "      <td>9</td>\n",
              "      <td>186</td>\n",
              "      <td>2</td>\n",
              "      <td>63</td>\n",
              "      <td>68</td>\n",
              "      <td>201</td>\n",
              "      <td>4</td>\n",
              "      <td>60</td>\n",
              "      <td>294</td>\n",
              "      <td>1272</td>\n",
              "      <td>1</td>\n",
              "      <td>214</td>\n",
              "      <td>7028</td>\n",
              "      <td>1253</td>\n",
              "      <td>5</td>\n",
              "      <td>3044</td>\n",
              "      <td>2057</td>\n",
              "      <td>2200</td>\n",
              "      <td>15</td>\n",
              "      <td>19</td>\n",
              "      <td>4863</td>\n",
              "      <td>2477</td>\n",
              "      <td>30</td>\n",
              "      <td>7029</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>541</td>\n",
              "      <td>1</td>\n",
              "      <td>5284</td>\n",
              "      <td>1</td>\n",
              "      <td>3128</td>\n",
              "      <td>9</td>\n",
              "      <td>53</td>\n",
              "      <td>12</td>\n",
              "      <td>349</td>\n",
              "      <td>15</td>\n",
              "      <td>55</td>\n",
              "      <td>982</td>\n",
              "      <td>10</td>\n",
              "      <td>3376</td>\n",
              "      <td>21</td>\n",
              "      <td>33</td>\n",
              "      <td>267</td>\n",
              "      <td>1</td>\n",
              "      <td>2432</td>\n",
              "      <td>23</td>\n",
              "      <td>20</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>2602</td>\n",
              "      <td>165</td>\n",
              "      <td>1</td>\n",
              "      <td>346</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>6576</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>1966</td>\n",
              "      <td>3</td>\n",
              "      <td>1712</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>1192</td>\n",
              "      <td>95</td>\n",
              "      <td>1967</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>12641</td>\n",
              "      <td>4486</td>\n",
              "      <td>903</td>\n",
              "      <td>703</td>\n",
              "      <td>6203</td>\n",
              "      <td>903</td>\n",
              "      <td>7032</td>\n",
              "      <td>12642</td>\n",
              "      <td>903</td>\n",
              "      <td>19550</td>\n",
              "      <td>12637</td>\n",
              "      <td>903</td>\n",
              "      <td>4072</td>\n",
              "      <td>10967</td>\n",
              "      <td>903</td>\n",
              "      <td>3210</td>\n",
              "      <td>3595</td>\n",
              "      <td>903</td>\n",
              "      <td>15009</td>\n",
              "      <td>4865</td>\n",
              "      <td>903</td>\n",
              "      <td>2434</td>\n",
              "      <td>10971</td>\n",
              "      <td>903</td>\n",
              "      <td>15010</td>\n",
              "      <td>4206</td>\n",
              "      <td>8153</td>\n",
              "      <td>903</td>\n",
              "      <td>10965</td>\n",
              "      <td>5285</td>\n",
              "      <td>1360</td>\n",
              "      <td>2</td>\n",
              "      <td>16</td>\n",
              "      <td>379</td>\n",
              "      <td>12</td>\n",
              "      <td>746</td>\n",
              "      <td>3</td>\n",
              "      <td>461</td>\n",
              "      <td>512</td>\n",
              "      <td>325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>2244</td>\n",
              "      <td>21</td>\n",
              "      <td>3480</td>\n",
              "      <td>6578</td>\n",
              "      <td>183</td>\n",
              "      <td>49</td>\n",
              "      <td>1008</td>\n",
              "      <td>44</td>\n",
              "      <td>363</td>\n",
              "      <td>15019</td>\n",
              "      <td>52</td>\n",
              "      <td>1</td>\n",
              "      <td>12647</td>\n",
              "      <td>12648</td>\n",
              "      <td>3130</td>\n",
              "      <td>650</td>\n",
              "      <td>17</td>\n",
              "      <td>1</td>\n",
              "      <td>1568</td>\n",
              "      <td>1744</td>\n",
              "      <td>331</td>\n",
              "      <td>8160</td>\n",
              "      <td>11</td>\n",
              "      <td>5</td>\n",
              "      <td>15020</td>\n",
              "      <td>7035</td>\n",
              "      <td>650</td>\n",
              "      <td>5</td>\n",
              "      <td>9803</td>\n",
              "      <td>1376</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>48</td>\n",
              "      <td>651</td>\n",
              "      <td>331</td>\n",
              "      <td>2959</td>\n",
              "      <td>1</td>\n",
              "      <td>2302</td>\n",
              "      <td>15021</td>\n",
              "      <td>12649</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 4491 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   0     1     2     3     4     5     ...  4485  4486  4487  4488   4489   4490\n",
              "0     0     0     0     0     0     0  ...    74    29   164    66     29    164\n",
              "1     0     0     0     0     0     0  ...    15    19  4863  2477     30   7029\n",
              "2     0     0     0     0     0     0  ...  1712     6     5  1192     95   1967\n",
              "3     0     0     0     0     0     0  ...    12   746     3   461    512    325\n",
              "4     0     0     0     0     0     0  ...   331  2959     1  2302  15021  12649\n",
              "\n",
              "[5 rows x 4491 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU18RBHg3u7i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "outputId": "3e8951ce-4a52-4f8a-e111-973a789613db"
      },
      "source": [
        "y_complete = pd.DataFrame(y)\n",
        "y_complete.head()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     0    1    2    3    4\n",
              "0  0.0  0.0  0.0  0.0  1.0\n",
              "1  1.0  0.0  0.0  0.0  0.0\n",
              "2  0.0  0.0  0.0  1.0  0.0\n",
              "3  0.0  0.0  0.0  1.0  0.0\n",
              "4  0.0  1.0  0.0  0.0  0.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2NlQBx93u7n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3153928b-caf3-4444-e91d-dda23ad8bc58"
      },
      "source": [
        "x_complete.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2225, 4491)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EFQZUOad3u7t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_complete.iloc[:1800,]\n",
        "y_train = y_complete.iloc[:1800,]\n",
        "x_test = x_complete.iloc[1800:,]\n",
        "y_test = y_complete.iloc[1800:,]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ftFgxlWh3u7x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 709
        },
        "outputId": "e02632ce-b994-4afa-eb28-7b27bd2804d9"
      },
      "source": [
        "early_stopping = EarlyStopping(monitor='val_loss', min_delta=0.01, patience=4, verbose=1)\n",
        "callbacks_list = [early_stopping]\n",
        "hist = model.fit(x_train, y_train, epochs=10, callbacks=callbacks_list, validation_split=0.1, shuffle=True,batch_size = 128)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "Train on 1620 samples, validate on 180 samples\n",
            "Epoch 1/10\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "1620/1620 [==============================] - 301s 186ms/step - loss: 0.8793 - acc: 0.7514 - val_loss: 0.4912 - val_acc: 0.8000\n",
            "Epoch 2/10\n",
            "1620/1620 [==============================] - 294s 181ms/step - loss: 0.4952 - acc: 0.8002 - val_loss: 0.4944 - val_acc: 0.8000\n",
            "Epoch 3/10\n",
            "1620/1620 [==============================] - 300s 185ms/step - loss: 0.4873 - acc: 0.8005 - val_loss: 0.4814 - val_acc: 0.8000\n",
            "Epoch 4/10\n",
            "1620/1620 [==============================] - 301s 186ms/step - loss: 0.4489 - acc: 0.8189 - val_loss: 0.4169 - val_acc: 0.8422\n",
            "Epoch 5/10\n",
            "1620/1620 [==============================] - 297s 184ms/step - loss: 0.3625 - acc: 0.8470 - val_loss: 0.3231 - val_acc: 0.8589\n",
            "Epoch 6/10\n",
            "1620/1620 [==============================] - 296s 183ms/step - loss: 0.2770 - acc: 0.8789 - val_loss: 0.2482 - val_acc: 0.8978\n",
            "Epoch 7/10\n",
            "1620/1620 [==============================] - 292s 180ms/step - loss: 0.1676 - acc: 0.9346 - val_loss: 0.1307 - val_acc: 0.9489\n",
            "Epoch 8/10\n",
            "1620/1620 [==============================] - 291s 180ms/step - loss: 0.0797 - acc: 0.9728 - val_loss: 0.0905 - val_acc: 0.9700\n",
            "Epoch 9/10\n",
            "1620/1620 [==============================] - 289s 179ms/step - loss: 0.0406 - acc: 0.9889 - val_loss: 0.0514 - val_acc: 0.9844\n",
            "Epoch 10/10\n",
            "1620/1620 [==============================] - 289s 178ms/step - loss: 0.0232 - acc: 0.9923 - val_loss: 0.0452 - val_acc: 0.9878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rdumKUq73u74",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(x_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rcgkVGoKV6Q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "687e5afd-4240-49c6-b018-f11d2e4eb5e3"
      },
      "source": [
        "result = model.evaluate(x_test,y_test)\n",
        "result"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "425/425 [==============================] - 18s 43ms/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.07815255165100098, 0.9755294213575475]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5ZfqgG9LV5F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1fb32077-af26-4991-cbf4-1ba4be618263"
      },
      "source": [
        "y_test.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(425, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CtNKH4MWGfEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "rounded_labels=np.argmax(np.array(y_test), axis=1)\n",
        "#rounded_pred = np.argmax(y_pred,axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KqsW5_h9L0sA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0bc01024-2810-4676-dbea-05cb1ded0b1b"
      },
      "source": [
        "rounded_labels.shape"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(425,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umZx5K6FHkSq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "report = classification_report(rounded_labels,rounded_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxbyOT-QHqSF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "76634013-cafc-4d7c-c510-cd5e868a1b86"
      },
      "source": [
        "print(report)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.96      0.93       103\n",
            "           1       0.91      0.85      0.88        60\n",
            "           2       0.93      0.93      0.93        82\n",
            "           3       0.98      0.93      0.95        97\n",
            "           4       0.96      0.99      0.98        83\n",
            "\n",
            "    accuracy                           0.94       425\n",
            "   macro avg       0.94      0.93      0.93       425\n",
            "weighted avg       0.94      0.94      0.94       425\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Y-iFDC2Ij8z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}